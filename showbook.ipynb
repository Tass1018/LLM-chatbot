{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9779a5cd8bbc411ca5c3460b37b6eeab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55464da9194c432c9ff2659391dbe862"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78f103a7c4e14a3e978a75718ee3b4a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "004fcef8fa534a9394680fba3a6fe91c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/Llama-2-7b-Chat-GGUF\")\n",
    "\n",
    "\n",
    "# get model and tokenizer from ctransformers\n",
    "model = AutoModelForCausalLM.from_pretrained(\"TheBloke/Llama-2-7b-Chat-GGUF\", hf=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain import PromptTemplate,  LLMChain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer= tokenizer,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                device_map=\"auto\",\n",
    "                max_new_tokens = 512,\n",
    "                do_sample=True,\n",
    "                top_k=30,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "                )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT ):\n",
    "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template\n",
    "\n",
    "def cut_off_text(text, prompt):\n",
    "    cutoff_phrase = prompt\n",
    "    index = text.find(cutoff_phrase)\n",
    "    if index != -1:\n",
    "        return text[:index]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_substring(string, substring):\n",
    "    return string.replace(substring, \"\")\n",
    "\n",
    "\n",
    "\n",
    "def generate(text):\n",
    "    prompt = get_prompt(text)\n",
    "    with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "        outputs = model.generate(**inputs,\n",
    "                                 max_new_tokens=512,\n",
    "                                 eos_token_id=tokenizer.eos_token_id,\n",
    "                                 pad_token_id=tokenizer.eos_token_id,\n",
    "                                 )\n",
    "        final_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        final_outputs = cut_off_text(final_outputs, '</s>')\n",
    "        final_outputs = remove_substring(final_outputs, prompt)\n",
    "\n",
    "    return final_outputs#, outputs\n",
    "\n",
    "def parse_text(text):\n",
    "        wrapped_text = textwrap.fill(text, width=100)\n",
    "        print(wrapped_text +'\\n\\n')\n",
    "        # return assistant_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline = pipe, model_kwargs = {'temperature':0})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m system_prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are an advanced assistant that excels at summarization and finding useful infomation from text. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m instruction \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse the following pieces of context to answer the question at the end. If you don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt know the answer, just say that you don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt know, don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthanks for asking!\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m at the end of the answer.\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;132;01m{context}\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124mQuestion: \u001B[39m\u001B[38;5;132;01m{question}\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124mHelpful Answer:\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m----> 6\u001B[0m template \u001B[38;5;241m=\u001B[39m \u001B[43mget_prompt\u001B[49m(instruction, system_prompt)\n\u001B[1;32m      8\u001B[0m prompt \u001B[38;5;241m=\u001B[39m PromptTemplate(template\u001B[38;5;241m=\u001B[39mtemplate, input_variables\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m      9\u001B[0m llm_chain \u001B[38;5;241m=\u001B[39m LLMChain(prompt\u001B[38;5;241m=\u001B[39mprompt, llm\u001B[38;5;241m=\u001B[39mllm)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'get_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are an advanced assistant that excels at summarization and finding useful infomation from text. \"\n",
    "instruction = \"\"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "template = get_prompt(instruction, system_prompt)\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5201\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://caesar.web.engr.illinois.edu/\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "persist_directory = 'docs/chroma/'\n",
    "\n",
    "\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "OPENAI_API_KEY = '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'\n",
    "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "# Create the vector store\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def scrape_website(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # text_data = [element.get_text().replace('\\n', ' \\n ') for element in soup.find_all(['body'])]\n",
    "    text_data = [element.get_text() for element in soup.find_all(['body'])]\n",
    "\n",
    "    return \" \".join(text_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "txt = scrape_website(\"https://caesar.web.engr.illinois.edu/\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 1:\n",
      "Matthew Caesar\n",
      "Professor \n",
      "Department of Computer Science\n",
      "University of Illinois at Urbana-Champaign\n",
      "Urbana, IL, 61801\n",
      "\n",
      "Email: caesar (at) cs (dot) illinois (dot) edu\n",
      "Office: Room 3118, Siebel Center \n",
      "Phone: 847-323-2968\n",
      "\n",
      "\n",
      "Links: \n",
      "[ Publications ]\n",
      "[ Bio ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I am a Professor in the Department of Computer Science at UIUC.\n",
      "I am also an Affiliate Professor in the  Department of Electrical and Computer Engineering, an Affiliate Research Professor in the Coordinated Science Laboratory, Affiliate Professor in the School of Information Sciences, and a member of the Information Trust Institute. \n",
      "I currently serve as the Vice Chair of ACM SIGCOMM, and the co-chair of The Networking Channel, an online community talk series for the computer systems and networking community. \n",
      "I co-founded and previously served as the Chief Science Officer and President of Veriflow (sold to VMware in 2019). \n",
      "I received my Ph.D. in Computer Science from UC Berkeley.  \n",
      "\n",
      "\n",
      "My research focuses on the design, analysis, and implementation of\n",
      "networked and distributed systems, with an emphasis on network\n",
      "virtualization, routing, network algorithms, systems security, and\n",
      "cloud services. I like taking a multi-pronged approach to system\n",
      "design, building systems that work well in practice but are grounded in\n",
      "strong theoretical principles. \n",
      "My recent work involves network security, network verification, and Internet of Things.\n",
      "For an overview of one of my projects please see this video.\n",
      "\n",
      " \n",
      "\n",
      "Section 2:\n",
      "Students \n",
      "\n",
      " Mubashir Anwar (PhD)  \n",
      " Yu-Ju Chang (MS)  \n",
      " Kuan-Yen (KY) Chou (PhD)  \n",
      " Shivram Gowtham(MS)  \n",
      " Xin Jin (MS)  \n",
      " Deepti Kalasapura (MS)  \n",
      " Yuantao Lu (MS)  \n",
      " Arpitha Raghunandan (MS)  \n",
      " Hongshuo Zhang (MS)  \n",
      "\n",
      " \n",
      "\n",
      "Section 3:\n",
      "Alumni \n",
      "\n",
      "\n",
      " Yifan (Vicky) Chen (MS 2023, Monad Labs)  \n",
      "  Gregory Lee (MS 2022, NVIDIA, Machine Learning)  \n",
      " Rahul Balakrishnan (MS 2021, Front)  \n",
      " Aniket Shirke (MS 2021, Google, Youtube Ads Ecosystem)  \n",
      " Bella Lee (MS 2021, Google)  \n",
      " Santhosh Prabhu (PhD 2020, VMware)  \n",
      " Umar Farooq (MS 2020, Amazon Cloud Services)  \n",
      " Wenxuan Zhou (PhD 2018, Senior Software Engineer, Network Verification Group, VMware)  \n",
      " Jason Croft (PhD 2018, Researcher, Forward Networks)  \n",
      " Zhichun Wan (MS 2019, Software Engineer, Cloud Development Group, Marklogic)   \n",
      " Rashid Tahir (PhD 2018, Assistant Professor, University of Prince Mugrin, Saudi Arabia)  \n",
      " Gohar Irfan Chaudhry (MS 2018, Systems and Networking Group, Microsoft Research)  \n",
      " Yongli Chen (MS 2017, Azure Cloud Core Networking Team, Microsoft)  \n",
      "  Fred Douglas (PhD 2017, Software Engineer (working on Internet Freedom), Google)  \n",
      " Hassan Shahid Khan (MS 2017, Software Engineer, Amazon)  \n",
      " Ahmed Khurshid (PhD 2015, Principal Engineer and Co-Founder, Veriflow Systems)  \n",
      " Kevin Jin (Postdoctoral Fellow, Assistant Professor, Illinois Institute of Technology) \n",
      " Anduo Wang (Postdoctoral Fellow, Assistant Professor, Temple University) \n",
      " Virajith Jalaparti (PhD 2015, Scientist, Cloud Information Services Laboratory, Microsoft) \n",
      " Jereme Lamps (MS 2015, Sandia National Labs, Cyber Security R&D) \n",
      " Chi-Yao Hong (PhD 2015, Google Core Network Architectures Group) \n",
      " Bobby Zhongbo Chen (MS 2015, Software Engineer, Growth Infrastructure Team, Dropbox) \n",
      " Chia-Chi Lin (PhD 2013, Facebook Research)\n",
      "Yiwei Yang (MS 2013, Yahoo! Labs, Champaign)\n",
      "\n",
      "Rachit Agarwal (PhD 2013, Assistant Professor, Cornell University) \n",
      " Joseph Leong (MS 2013, MIT Lincoln Laboratory)\n",
      " Firat Kiyak (MS 2009, Microsoft, Windows Core Networking Team)\n",
      " Brent Mochizuki (MS 2010, UC Berkeley Space Sciences Lab)\n",
      "\n",
      " \n",
      "\n",
      "Section 4:\n",
      "Teaching \n",
      "\n",
      "CS 498IT -- Internet of Things [Spring 2019] [Fall 2019] [Spring 2020] [Fall 2020] \n",
      " CS 436 -- Systems and Networking Laboratory, [Fall 2009], [Spring 2012], [Fall 2017],  [Spring 2018],  [Fall 2018]  \n",
      "CS 598 -- Network Security,\t[Spring 2013] CS 598 -- Advanced Internetworking, [Fall 2008] [Spring 2011]\n",
      "CS 591AoS -- Acting Out Algorithms [Spring 2013] [Fall 2013]\n",
      " CS 438 -- Communication Networks, [Spring 2009] [Spring 2010] [Spring 2014]\n",
      " CS 241 -- System Programming, [Fall 2011]  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indices = [(m.start(0), m.end(0)) for m in re.finditer(r'cAlumni|Students|Teaching', txt)]\n",
    "\n",
    "# Create a list to store the sections\n",
    "sections = []\n",
    "\n",
    "# Extract the sections based on the indices of the headings\n",
    "for i, (start, end) in enumerate(indices):\n",
    "    if i < len(indices) - 1:\n",
    "        sections.append(txt[start:indices[i+1][0]])\n",
    "    else:\n",
    "        sections.append(txt[start:])\n",
    "\n",
    "# Print each section\n",
    "for i, section in enumerate(sections):\n",
    "    print(f\"Section {i+1}:\\n{section}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(' \\n\\n')\n",
    "chunks = splitter.split_text(txt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "'Matthew Caesar\\nProfessor \\nDepartment of Computer Science\\nUniversity of Illinois at Urbana-Champaign\\nUrbana, IL, 61801\\n\\nEmail: caesar (at) cs (dot) illinois (dot) edu\\nOffice: Room 3118, Siebel Center \\nPhone: 847-323-2968\\n\\n\\nLinks: \\n[ Publications ]\\n[ Bio ]\\n\\n\\n\\n\\n\\nI am a Professor in the Department of Computer Science at UIUC.\\nI am also an Affiliate Professor in the  Department of Electrical and Computer Engineering, an Affiliate Research Professor in the Coordinated Science Laboratory, Affiliate Professor in the School of Information Sciences, and a member of the Information Trust Institute. \\nI currently serve as the Vice Chair of ACM SIGCOMM, and the co-chair of The Networking Channel, an online community talk series for the computer systems and networking community. \\nI co-founded and previously served as the Chief Science Officer and President of Veriflow (sold to VMware in 2019). \\nI received my Ph.D. in Computer Science from UC Berkeley.  \\n\\n\\nMy research focuses on the design, analysis, and implementation of\\nnetworked and distributed systems, with an emphasis on network\\nvirtualization, routing, network algorithms, systems security, and\\ncloud services. I like taking a multi-pronged approach to system\\ndesign, building systems that work well in practice but are grounded in\\nstrong theoretical principles. \\nMy recent work involves network security, network verification, and Internet of Things.\\nFor an overview of one of my projects please see this video.\\n\\n Students \\n\\n Mubashir Anwar (PhD)  \\n Yu-Ju Chang (MS)  \\n Kuan-Yen (KY) Chou (PhD)  \\n Shivram Gowtham(MS)  \\n Xin Jin (MS)  \\n Deepti Kalasapura (MS)  \\n Yuantao Lu (MS)  \\n Arpitha Raghunandan (MS)  \\n Hongshuo Zhang (MS)  \\n\\n Alumni \\n\\n\\n Yifan (Vicky) Chen (MS 2023, Monad Labs)  \\n  Gregory Lee (MS 2022, NVIDIA, Machine Learning)  \\n Rahul Balakrishnan (MS 2021, Front)  \\n Aniket Shirke (MS 2021, Google, Youtube Ads Ecosystem)  \\n Bella Lee (MS 2021, Google)  \\n Santhosh Prabhu (PhD 2020, VMware)  \\n Umar Farooq (MS 2020, Amazon Cloud Services)  \\n Wenxuan Zhou (PhD 2018, Senior Software Engineer, Network Verification Group, VMware)  \\n Jason Croft (PhD 2018, Researcher, Forward Networks)  \\n Zhichun Wan (MS 2019, Software Engineer, Cloud Development Group, Marklogic)   \\n Rashid Tahir (PhD 2018, Assistant Professor, University of Prince Mugrin, Saudi Arabia)  \\n Gohar Irfan Chaudhry (MS 2018, Systems and Networking Group, Microsoft Research)  \\n Yongli Chen (MS 2017, Azure Cloud Core Networking Team, Microsoft)  \\n  Fred Douglas (PhD 2017, Software Engineer (working on Internet Freedom), Google)  \\n Hassan Shahid Khan (MS 2017, Software Engineer, Amazon)  \\n Ahmed Khurshid (PhD 2015, Principal Engineer and Co-Founder, Veriflow Systems)  \\n Kevin Jin (Postdoctoral Fellow, Assistant Professor, Illinois Institute of Technology) \\n Anduo Wang (Postdoctoral Fellow, Assistant Professor, Temple University) \\n Virajith Jalaparti (PhD 2015, Scientist, Cloud Information Services Laboratory, Microsoft) \\n Jereme Lamps (MS 2015, Sandia National Labs, Cyber Security R&D) \\n Chi-Yao Hong (PhD 2015, Google Core Network Architectures Group) \\n Bobby Zhongbo Chen (MS 2015, Software Engineer, Growth Infrastructure Team, Dropbox) \\n Chia-Chi Lin (PhD 2013, Facebook Research)\\nYiwei Yang (MS 2013, Yahoo! Labs, Champaign)\\n\\nRachit Agarwal (PhD 2013, Assistant Professor, Cornell University) \\n Joseph Leong (MS 2013, MIT Lincoln Laboratory)\\n Firat Kiyak (MS 2009, Microsoft, Windows Core Networking Team)\\n Brent Mochizuki (MS 2010, UC Berkeley Space Sciences Lab)\\n\\n Teaching'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "Matthew Caesar\n",
      "Professor \n",
      "Department of Computer Science\n",
      "University of Illinois at Urbana-Champaign\n",
      "Urbana, IL, 61801\n",
      "\n",
      "Email: caesar (at) cs (dot) illinois (dot) edu\n",
      "Office: Room 3118, Siebel Center \n",
      "Phone: 847-323-2968\n",
      "\n",
      "\n",
      "Links: \n",
      "[ Publications ]\n",
      "[ Bio ]\n",
      "\n",
      "I am a Professor in the Department of Computer Science at UIUC.\n",
      "I am also an Affiliate Professor in the  Department of Electrical and Computer Engineering, an Affiliate Research Professor in the Coordinated Science Laboratory, Affiliate Professor in the School of Information Sciences, and a member of the Information Trust Institute. \n",
      "I currently serve as the Vice Chair of ACM SIGCOMM, and the co-chair of The Networking Channel, an online community talk series for the computer systems and networking community. \n",
      "I co-founded and previously served as the Chief Science Officer and President of Veriflow (sold to VMware in 2019). \n",
      "I received my Ph.D. in Computer Science from UC Berkeley.  \n",
      "\n",
      "\n",
      "My research focuses on the design, analysis, and implementation of\n",
      "networked and distributed systems, with an emphasis on network\n",
      "virtualization, routing, network algorithms, systems security, and\n",
      "cloud services. I like taking a multi-pronged approach to system\n",
      "design, building systems that work well in practice but are grounded in\n",
      "strong theoretical principles. \n",
      "My recent work involves network security, network verification, and Internet of Things.\n",
      "For an overview of one of my projects please see this video.\n",
      "\n",
      " Students \n",
      "\n",
      " Mubashir Anwar (PhD)  \n",
      " Yu-Ju Chang (MS)  \n",
      " Kuan-Yen (KY) Chou (PhD)  \n",
      " Shivram Gowtham(MS)  \n",
      " Xin Jin (MS)  \n",
      " Deepti Kalasapura (MS)  \n",
      " Yuantao Lu (MS)  \n",
      " Arpitha Raghunandan (MS)  \n",
      " Hongshuo Zhang (MS)  \n",
      "\n",
      " Alumni \n",
      "\n",
      "\n",
      " Yifan (Vicky) Chen (MS 2023, Monad Labs)  \n",
      "  Gregory Lee (MS 2022, NVIDIA, Machine Learning)  \n",
      " Rahul Balakrishnan (MS 2021, Front)  \n",
      " Aniket Shirke (MS 2021, Google, Youtube Ads Ecosystem)  \n",
      " Bella Lee (MS 2021, Google)  \n",
      " Santhosh Prabhu (PhD 2020, VMware)  \n",
      " Umar Farooq (MS 2020, Amazon Cloud Services)  \n",
      " Wenxuan Zhou (PhD 2018, Senior Software Engineer, Network Verification Group, VMware)  \n",
      " Jason Croft (PhD 2018, Researcher, Forward Networks)  \n",
      " Zhichun Wan (MS 2019, Software Engineer, Cloud Development Group, Marklogic)   \n",
      " Rashid Tahir (PhD 2018, Assistant Professor, University of Prince Mugrin, Saudi Arabia)  \n",
      " Gohar Irfan Chaudhry (MS 2018, Systems and Networking Group, Microsoft Research)  \n",
      " Yongli Chen (MS 2017, Azure Cloud Core Networking Team, Microsoft)  \n",
      "  Fred Douglas (PhD 2017, Software Engineer (working on Internet Freedom), Google)  \n",
      " Hassan Shahid Khan (MS 2017, Software Engineer, Amazon)  \n",
      " Ahmed Khurshid (PhD 2015, Principal Engineer and Co-Founder, Veriflow Systems)  \n",
      " Kevin Jin (Postdoctoral Fellow, Assistant Professor, Illinois Institute of Technology) \n",
      " Anduo Wang (Postdoctoral Fellow, Assistant Professor, Temple University) \n",
      " Virajith Jalaparti (PhD 2015, Scientist, Cloud Information Services Laboratory, Microsoft) \n",
      " Jereme Lamps (MS 2015, Sandia National Labs, Cyber Security R&D) \n",
      " Chi-Yao Hong (PhD 2015, Google Core Network Architectures Group) \n",
      " Bobby Zhongbo Chen (MS 2015, Software Engineer, Growth Infrastructure Team, Dropbox) \n",
      " Chia-Chi Lin (PhD 2013, Facebook Research)\n",
      "Yiwei Yang (MS 2013, Yahoo! Labs, Champaign)\n",
      "\n",
      "Rachit Agarwal (PhD 2013, Assistant Professor, Cornell University) \n",
      " Joseph Leong (MS 2013, MIT Lincoln Laboratory)\n",
      " Firat Kiyak (MS 2009, Microsoft, Windows Core Networking Team)\n",
      " Brent Mochizuki (MS 2010, UC Berkeley Space Sciences Lab)\n",
      "\n",
      " Teaching\n",
      "\n",
      "Teaching \n",
      "\n",
      "CS 498IT -- Internet of Things [Spring 2019] [Fall 2019] [Spring 2020] [Fall 2020] \n",
      " CS 436 -- Systems and Networking Laboratory, [Fall 2009], [Spring 2012], [Fall 2017],  [Spring 2018],  [Fall 2018]  \n",
      "CS 598 -- Network Security,\t[Spring 2013] CS 598 -- Advanced Internetworking, [Fall 2008] [Spring 2011]\n",
      "CS 591AoS -- Acting Out Algorithms [Spring 2013] [Fall 2013]\n",
      " CS 438 -- Communication Networks, [Spring 2009] [Spring 2010] [Spring 2014]\n",
      " CS 241 -- System Programming, [Fall 2011]\n",
      "\n",
      "//////////////////\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recombined_chunks = ['\\n\\n'.join(chunks[i:i+4]) for i in range(0, len(chunks), 4)]\n",
    "\n",
    "for i, chunk in enumerate(recombined_chunks):\n",
    "    print(f\"Chunk {i+1}:\\n{chunk}\\n\")\n",
    "    print(f\"//////////////////\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Bprompt takes in the documents and the question and passes it to a language model.\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\".\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)# Run chain\n",
    "\n",
    "\n",
    "# Initilaize chain\n",
    "# Set return_source_documents to True to get the source document\n",
    "# Set chain_type to prompt template defines\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "' Thanks for asking! Matthew Caesar is the professor.'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass question to the qa_chain\n",
    "question = \"Who is the professor?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT ):\n",
    "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template\n",
    "\n",
    "def cut_off_text(text, prompt):\n",
    "    cutoff_phrase = prompt\n",
    "    index = text.find(cutoff_phrase)\n",
    "    if index != -1:\n",
    "        return text[:index]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_substring(string, substring):\n",
    "    return string.replace(substring, \"\")\n",
    "\n",
    "\n",
    "\n",
    "def generate(text):\n",
    "    prompt = get_prompt(text)\n",
    "    with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "        outputs = model.generate(**inputs,\n",
    "                                 max_new_tokens=512,\n",
    "                                 eos_token_id=tokenizer.eos_token_id,\n",
    "                                 pad_token_id=tokenizer.eos_token_id,\n",
    "                                 )\n",
    "        final_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        final_outputs = cut_off_text(final_outputs, '</s>')\n",
    "        final_outputs = remove_substring(final_outputs, prompt)\n",
    "\n",
    "    return final_outputs#, outputs\n",
    "\n",
    "def parse_text(text):\n",
    "        wrapped_text = textwrap.fill(text, width=100)\n",
    "        print(wrapped_text +'\\n\\n')\n",
    "        # return assistant_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]<<SYS>>\n",
      "You are an advanced assistant that excels at summarization and understanding. \n",
      "<</SYS>>\n",
      "\n",
      "Use the following pieces of context to summarize. If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
      "\n",
      " {context} \n",
      "\n",
      " [/INST]\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMChain\nvectordb\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(template)\n\u001B[1;32m      7\u001B[0m prompt \u001B[38;5;241m=\u001B[39m PromptTemplate(template\u001B[38;5;241m=\u001B[39mtemplate, input_variables\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m----> 8\u001B[0m llm_chain \u001B[38;5;241m=\u001B[39m \u001B[43mLLMChain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvectordb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvectordb\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/LLM/lib/python3.10/site-packages/langchain/load/serializable.py:75\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 75\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lc_kwargs \u001B[38;5;241m=\u001B[39m kwargs\n",
      "File \u001B[0;32m~/.conda/envs/LLM/lib/python3.10/site-packages/pydantic/main.py:341\u001B[0m, in \u001B[0;36mpydantic.main.BaseModel.__init__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValidationError\u001B[0m: 1 validation error for LLMChain\nvectordb\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate,  LLMChain\n",
    "system_prompt = \"You are an advanced assistant that excels at summarization and understanding. \"\n",
    "instruction = \"Use the following pieces of context to summarize. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\\n {context} \\n\\n \"\n",
    "template = get_prompt(instruction, system_prompt)\n",
    "print(template)\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True, vectordb=vectordb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = \"who is the professor?\"\n",
    "output = llm_chain.run(text)\n",
    "\n",
    "parse_text(output)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
